# General
test_mode: False
debug: True
run_num: 0
explicit_run_enumeration: False
machine: "local"
device: "cuda"
workdir: "/mnt/d/Aptamer RL/ActiveLearningPipeline/Runs"
# Seeds
seeds:
  sampler: 0
  model: 0
  dataset: 0
  toy_oracle: 0
# Dataset
dataset:
  oracle: "nupack energy"
  type: "toy"
  init_length: 100
  dict_size: 4
  variable_length: True
  min_length: 10
  max_length: 40
  sample_tasks: 1
# AL
al:
  sample_method: "mcmc"
  query_mode: "fancy_acquisition" # must be 'fancy_acquisition' for our new acquisition functions
  acquisition_function : "ei"
  hyperparams_learning: False
  n_iter: 10
  query_selection: "argmin"
  minima_dist_cutoff: 0.25
  energy_uncertainty_tradeoff: 0
  UCB_kappa: 0.1
  EI_max_percentile: 80
  queries_per_iter: 100
  mode: "training"
  q_batch_size: 32
  buffer_size: 10000
  episodes: 1
  action_state_size: 9
  comet:
    project: aptamer-al-mk
    tags:
      - GPU_gfn_test
# Querier
querier:
  model_state_size: 30
  opt: "SGD"
  momentum: 0.95
  model_ckpt: !!null
  latent_space_width: 10
# GFlowNet # model.pt
gflownet:
  device: "cuda"
  model_ckpt: !!null #model.pt
  progress: True
  opt: "adam"
  adam_beta1: 0.9
  adam_beta2: 0.999
  momentum: 0.9
  mbsize: 128
  train_to_sample_ratio: 1
  n_hid: 256
  n_layers: 2
  n_iter: 20000
  n_samples: 10000
  num_empirical_loss: 200000
  batch_reward: True
  bootstrap_tau: 0.0
  clip_grad_norm: 0.0
  annealing: False
  post_annealing_samples: 100
  post_annealing_time: 1000
  min_word_len: 1
  max_word_len: 1
  early_stopping: 0.001
  ema_alpha: 0.5
  learning_rate: 0.0001
  ckpt_period: 100
  reward_beta_init: 1
  reward_beta_mult: 1.25
  reward_beta_period: 100
  reward_max: 50000
  test:
    path: !!null
    period: 100
# Proxy model
proxy:
  model_type: "mlp"
  ensemble_size: 1
  width: 128
  n_layers: 4
  mbsize: 10
  max_epochs: 200
  shuffle_dataset: True
  uncertainty_estimation : "dropout"
  dropout: 0.1
  dropout_samples: 25
# MCMC
mcmc:
  sampling_time: 200
  num_samplers: 20
  stun_min_gamma: -3
  stun_max_gamma: 1
