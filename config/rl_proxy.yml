# General
test_mode: False
debug: False
run_num: 0
explicit_run_enumeration: False
machine: "local"
device: "cuda"
workdir: "/mnt/d/Aptamer RL/ActiveLearningPipeline/Runs"
exp_name: gym_lunar_lander
# Seeds
seeds:
  sampler: 0
  model: 0
  dataset: 0
  toy_oracle: 0
# Dataset
dataset:
  oracle: "inner product"
  type: "toy"
  init_length: 100
  dict_size: 4
  variable_length: True
  min_length: 10
  max_length: 40
  sample_tasks: 1

# AL
al:
  sample_method: "random"
  query_mode: "learned" # must be 'fancy_acquisition' for our new acquisition functions
  num_random_samples: 10000
  annealing_samples: 50 # short MCMC on this many samples
  annealing_time: 100
  acquisition_function: null
  hyperparams_learning: True
  n_iter: 10
  query_selection: "argmin"
  minima_dist_cutoff: 0.25
  energy_uncertainty_tradeoff: 0
  UCB_kappa: 0.1
  EI_max_percentile: 80
  queries_per_iter: 100
  mode: "train_rl"
  comet:
    project: aptamer-al-RL
    tags:
      - inner-product
      - validate-rl
# RL Agent
rl:
  mode: train_rl
  dqn_batch_size: 4
  action_size: 9
  hidden_size: 128
  episodes: 100000
  gamma: 0.95 # discount factor
  alpha: 0.001 # learning rate
  lr_gamma: 0.99
  lr_step: 100
  eps_start: 1
  eps_end: 0.2
  eps_decay: 0.995
  buffer_size: 100000
  min_memory: 5
  tau: 0.1 # target network soft update hyperparameter SET to 1 FOR HARD UPDATE
  dqn_epochs: 10
  dqn_train_frequency: 1
  eval_interval: 50
  eval_steps: 5
  max_grad_norm: 10
  learning_start: 1
  log_rl_to_console: 1 # 1 for true, 0 for false
  seed: 1
  calculate_baseline: True

# Querier
querier:
  model_state_size: 30
  opt: "Adam"
  momentum: 0.95
  model_ckpt: !!null
  latent_space_width: 10
# GFlowNet # model.pt
gflownet:
  device: "cuda"
  model_ckpt: !!null #model.pt


  progress: True
  opt: "adam"
  adam_beta1: 0.9
  adam_beta2: 0.999
  momentum: 0.9
  mbsize: 128
  train_to_sample_ratio: 1
  n_hid: 256
  n_layers: 2
  n_iter: 20000
  n_samples: 10000
  num_empirical_loss: 200000
  batch_reward: True
  bootstrap_tau: 0.0
  clip_grad_norm: 0.0
  annealing: False
  post_annealing_samples: 100
  post_annealing_time: 1000
  min_word_len: 1
  max_word_len: 1
  early_stopping: 0.001
  ema_alpha: 0.5
  learning_rate: 0.0001
  ckpt_period: 100
  reward_beta_init: 1
  reward_beta_mult: 1.25
  reward_beta_period: 100
  reward_max: 50000
  test:
    path: !!null
    period: 100
# Proxy model
proxy:
  model_type: "mlp"
  ensemble_size: 1
  width: 64
  n_layers: 2
  mbsize: 10
  max_epochs: 200
  shuffle_dataset: True
  uncertainty_estimation: "dropout"
  dropout: 0.1
  dropout_samples: 5
# MCMC
mcmc:
  sampling_time: 5000 # 1000-10000
  num_samplers: 20 # 10-40
  stun_min_gamma: -3
  stun_max_gamma: 1
